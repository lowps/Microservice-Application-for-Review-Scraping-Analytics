#baseline, edit it later for usage if i decide to follow through on incorporating 
#scraper code on its own container. 
#Separation of concerns	wrt Scraper (vs) displaying front end (django_gunicorn)

#This code below could be all wrong, it was a quick write up, verify later if i use it
FROM python:3.10-slim

# Install Chrome + ChromeDriver
RUN apt-get update && apt-get install -y \
    wget unzip curl gnupg \
    && wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb \
    && dpkg -i google-chrome*.deb || apt-get -fy install \
    && rm google-chrome*.deb

RUN CHROME_VERSION=$(google-chrome --version | grep -oP '\d+\.\d+\.\d+') && \
    DRIVER_VERSION=$(curl -sS https://chromedriver.storage.googleapis.com/LATEST_RELEASE_${CHROME_VERSION}) && \
    wget -O /tmp/chromedriver.zip https://chromedriver.storage.googleapis.com/${DRIVER_VERSION}/chromedriver_linux64.zip && \
    unzip /tmp/chromedriver.zip -d /usr/local/bin && \
    chmod +x /usr/local/bin/chromedriver && \
    rm /tmp/chromedriver.zip

# Setup working dir
WORKDIR /app

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

#better practice is to place this in a single bash script file and 
#turn it into a cli commands with flags specifying if I want to -yes -no 
#the specified python script
CMD ["python", "ii_stage_data.py"]
CMD ["python", "iii_data_pre_processing.py"]
CMD ["python", "iv_data_final_processing.py"]
